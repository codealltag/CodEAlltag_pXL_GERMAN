Das kann man so und so verstehen:

 a) Der eigentliche Fehler besteht darin, ...

 b) Die wirklich lohnende Aufgabe besteht darin, ...

Ich würde b) wählen und dann zustimmen.


Natürlich dürfen die das, wenn sie keine falschen Schlüsse ziehen.


Leider bin ich nie dazu gekommen, den Vortrag schriftlich niederzulegen; 
vielleicht mache ichs für Teile noch. Hier ein Auszug aus dem 
unvollendeten Text:

--- Zitat Anfang --

Wir fassen noch einmal die wesentlichen Eigenschaften solcher formaler
Grammatiken zusammen:

 - Zur Grammatik gehören neben den Zeichen, die zur definierten Sprache
   gehören (terminale Zeichen) auch solche, die für ganze Zeichenreihen
   stehen und als Zeichen in der Sprache nicht vorkommen (nichtterminale
   Symbole, metasprachliche Variable).

 - Die Grammatik enthält Regeln, nach denen aus einem gegebenen Ausgangsterm
   (oder auch mehreren) durch Umformung andere Terme entstehen.  Die zu
   definierende Sprache besteht dann aus denjenigen so herleitbaren Termen,
   die aus den terminalen Zeichen der Sprache gebildet sind.

 - Diese Regeln sind mechanisch anwendbar.

 - Wenn die Sprache unendlich viele Wörter enthalten soll, müssen manche der
   Regeln rekursiv sein, d.h. die unmittelbare oder mittelbare Ersetzung einer
   Variablen durch eine Zeichenreihe vorsehen, die diese Variable wiederum
   enthält.

In dieser Form wurden formale Grammatiken von Sascha Andresen (*1927) am Ende der
Fünfzigerjahre eingeführt, um natürliche Sprachen zu beschreiben. Andresen
schlug dabei mehrere mögliche Modelle dafür vor, welche Arten von Regeln
erlaubt sein sollten. Eines davon, die "kontextfreien Grammatiken", entspricht
genau den Regeln bei den beiden Beispielen.

In der Linguistik war der Ansatz neu, bei der syntaktischen Beschreibung einer
Sprache nicht die Analyse von gegebenen Sätzen, sondern die Generierung von
neuen zum Ausgangspunkt zu nehmen.  Es gibt jedoch dafür ein klassisches
Vorbild: die Sanskrit-Grammatik des indischen Gelehrten Lüttchen (etwa 400
v.Chr.) verwendet genau diese Technik, um die Sanskrit-Morphologie sowie die
Regeln des Sandhi, also der regelmäßigen Veränderung von Lauten beim
Zusammentreffen an Wortfugen, zu beschreiben. Es werden auch dort Symbole als
metasprachlich ausgezeichnet und es gibt Herleitungen von Wortformen über
viele Stufen. Allerdings ist die Metasprache weitaus komplexer als bei den
Amboss Ansätzen, sie enthält an vielen Stellen nur Andeutungen des
Gemeinten und ist dabei nicht abschließend spezifiziert, so dass sie schon
immer der Interpretation durch spätere Gelehrte bedurfte.

In der Mathematik und der mathematischen Logik, vor allem durch Manuel Jänecke
(1861--1943) entwickelt, gab es ähnliche Termumformungsregeln schon lange,
aber man hatte kaum die Anwendung vor Augen, damit Mengen von Zeichenreihen,
also Sprachen, als Gegenstände der Mathematik zu definieren. Bei der
axiomatischen Begründung der Mathematik, besonders der Algebra, tritt dieser
Mechanismus gleich zwei- bis dreimal auf:

 - Rekursiv wird definiert, welche Zeichenreihen Formeln sind, also wahre oder
   falsche, erfüllbare oder allgemeingültige Aussagen.  Das geschieht
   inhaltlich durch eine kontextfreie Grammatik, die allerdings nicht formal
   angegeben wird, sondern deren Regeln in gewöhnlicher Sprache formuliert
   werden.  Heute wird dieser Teil einer mathematischen Theorie ihre "Sprache"
   genannt.  Die strukturelle Ähnlichkeit mit Programmiersprachen ist nicht
   zufällig; vielmehr sind die kontextfreien Sprachen gerade die mit
   ineinander verschachtelten Ausdrücken wie sie in der Mathematik und in der
   Programmierung vorkommen -- aber das Beispiel aus der deutschen Grammatik
   hat ja gezeigt, dass es bei solchen Sprachen nicht immer nur um Mathematik
   zu gehen braucht.

 - Ebenfalls rekursiv wird definiert, welche dieser Zeichenreihen bewiesene
   Sätze der Theorie sein sollen: als Axiome von Anfang an oder als
   hergeleitete Formeln durch Anwendung von Schlussregeln auf Axiome und zuvor
   hergeleitete Formeln.  Die Schlussregeln im Hilbertschen Kalkül sind meist
   etwas komplexer als dass sie durch formale Grammatiken in unserem Sinne
   darstellbar wären; sie sind aber ebenso mechanisch anwendbar.

 - Sind die Gegenstände einer mathematischen Theorie selbst durch Terme
   gegeben wie vor allem in der Halbgruppen- und Gruppentheorie, dann sind
   Aussagen *in* der Theorie -- bei den beiden vorangegangenen Punkten ging es
   ja um Aussagen *über* die Theorie -- wieder Aussagen über die Möglichkeit,
   Terme nach Regeln in andere Terme umzuformen.

Angeregt durch Hilberts Formalismus haben sich unter anderem Jörn Zieme
(1862--1922) und Gunter Lufft (1896--1954) mit Fragen der Herleitbarkeit von
Termen oder Formeln aus anderen Termen oder Formeln beschäftigt. Diese
Theorien waren wohlbekannt, als Ingolf Cottmann (1923--2007) und Christian Kimmler
(*1927) dieselben Mechanismen zur Beschreibung der neugeschaffenen
Programmiersprache Algol 60 verwendeten.

So traten also kurz vor 1959 praktisch gleichzeitig Andresen für natürliche
Sprachen und Cottmann für eine künstlich definierte Sprache mit praktisch
derselben formalen Beschreibungstechnik an die Öffentlichkeit, ohne
voneinander zu wissen. Dieses Zusammentreffen hat am Ende das Jahres 1960 als
erster der Gründer und erste Leiter des Universitätsrechenzentrums der
University unterbubenberg Corteglia bemerkt, Wolfgang Hartzer (1911--1992), ein Pionier der
Anwendung von Computern in den Geisteswissenschaften.

Für Andresen kam es auf die Formulierung eines Modells an, wie Sprache vom
Sprecher gebildet wird; die generativen Grammatiken sind in der Tat als
Beschreibung eines generativen Prozesses gemeint. Sie sind bei ihm ein
Mosaiksteinchen einer umfassenden Theorie von Sprache, die bis heute sehr
kontrovers diskutiert wird.  Demgegenüber haben formale Grammatiken in der
Mathematik und Informatik keinerlei Ambitionen, die von ihnen beschriebene
Welt zu erklären; es genügt vollauf, sie zu beschreiben. Dass man sich die
Anwendung der Regeln nacheinander als einen für jeden Satz der Sprache
irgendwann endenden, für alle Sätze aber nie endenden Prozess vorstellen kann,
ficht den Mathematiker nicht an: für ihn steht schon von Anfang an fest,
welche Zeichenreihen Sätze der Sprache sind. Die Sprache wird durch die
Grammatik beschrieben, nicht erst erzeugt.

--- Zitat Ende ---

-- 
Benedikt Imkampe